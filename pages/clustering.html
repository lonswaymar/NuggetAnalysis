<!DOCTYPE html>
<html>
<head>
    <title>Clustering - Nugget Analysis</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata">
    <style>
        body, html {
          height: 100%;
          font-family: "Georgia", sans-serif;
        }
    </style>
</head>
<body>

<!-- Navbar -->
<div class="w3-top">
    <div class="w3-row w3-padding w3-black">
        <div class="w3-col s2"><a href="../index.html" class="w3-button w3-block w3-black">Introduction</a></div>
        <div class="w3-col s2"><a href="arm.html" class="w3-button w3-block w3-black">ARM</a></div>
        <div class="w3-col s2"><a href="pca.html" class="w3-button w3-block w3-black">PCA</a></div>
        <div class="w3-col s2"><a href="clustering.html" class="w3-button w3-block w3-black">Clustering</a></div>
        <div class="w3-col s2"><a href="regression.html" class="w3-button w3-block w3-black">Regression</a></div>
        <div class="w3-col s2"><a href="naivebayes.html" class="w3-button w3-block w3-black">Naive Bayes</a></div>
        <div class="w3-col s2"><a href="decisiontree.html" class="w3-button w3-block w3-black">Decision Tree</a></div>
        <div class="w3-col s2"><a href="conclusion.html" class="w3-button w3-block w3-black">Conclusion</a></div>
    </div>
</div>

<!-- Page Content -->
<div class="w3-sand w3-grayscale w3-large">
    <div class="w3-container" id="model3" style="margin-top:75px;>
        <div class="w3-content" style="max-width:700px">
            <h5 class="w3-center w3-padding-64"><span class="w3-tag w3-wide">Clustering</span></h5>
            
            <strong>KMeans Clustering</strong>
            <p>To apply Kmeans clustering, I began by getting the career statistics of two different populations of NBA players.
            The first population of career statistics were gathered from the <code>alltimeleadersgrids</code> endpoint. This allowed me to grab
            the player names and IDs of the top 10 athletes of all time in scoring and assists.
            </p>
            <p>The second population of data I gathered were from all currently active athletes in the NBA. I then filtered out the IDs of 
            individuals in both categories. For example, LeBron James was present in the top 10 scorers of all time, and is still actively playing.
            Thus, I removed his name from the list of all active players. 
            </p>
            
            <p>
            My goal at this part of the analysis was to determine if the all time leaders in points and assists were <strong>from a different population</strong>
            than their modern-day peers that aren't in the leadership board but still have played the most minutes. After grabbing the career stats For
            all active players from the <code>PlayerCareerStats</code> endpoint, I then merged the two datasets into the a dataframe I used for the rest
            of the Kmeans analysis. Note that I've added the label <code>LEADER</code> but that this label is dropped when applying the Kmeans algorithm.
            </p>
            
            <div style="overflow-x: auto; border: 1px solid #ccc; padding: 8px; max-height: 300px;">
                <table class="w3-table w3-bordered w3-small">
                    <thead>
                        <tr>
                            <th>MIN</th>
                            <th>PTS</th>
                            <th>AST</th>
                            <th>LEADER</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>2498.0</td>
                            <td>862.0</td>
                            <td>168.0</td>
                            <td>NONLEADER</td>
                        </tr>
                        <tr>
                            <td>48654.0</td>
                            <td>33643.0</td>
                            <td>6306.0</td>
                            <td>LEADER</td>
                        </tr>
                        <tr>
                            <td>2133.0</td>
                            <td>666.0</td>
                            <td>303.0</td>
                            <td>NONLEADER</td>
                        </tr>
                    </tbody>
                </table>
            </div>


      
            <p>Before implementing KMeans, however, I noticed it wouldn't be fair to compare the stats leaders to just any other athlete (afterall, some athletes come off the bench for their entire career).
            So, I only used NBA players whose current playing time exceeds the 90th percentile in minutes played. A histogram of the <code>MIN</code> column from the cleaned dataset is plotted below. I've used
            a vertical line to mark the 90th percentile in minutes. By eye, we can clearly see a right skewed distribution with the amount of players rapidly diminishing as minutes played increases. 
            </p>
        
            <div class="w3-center">
                <img src="../images/module2_images/minutes_played_all_players.png" class="w3-image" style="width:70%;">
            </div>

            <p>Note the exponential drop-off in minutes — I believe that this means that it's increasingly difficult to sustain a long NBA career. 
            Yet, there are still many productive players who haven’t cracked the top 10 in points or assists.
            </p>

            <p>Below is a labeled scatter plot of total career assists versus total career points for both groups of athletes. The leaders' data is color coded green. 
            The 90th percentile of active players is grey. 
            </p>

            <div class="w3-center">
                <img src="../images/module2_images/pts_asts_scatter.png" class="w3-image" style="width:70%;">
            </div>

            <p>By eye, it's challenging to see if there are distinct clusters in the data. Can KMeans clustering identify the leaders versus the top currently played athletes? 
            To assess this, I standardized the data with the <code>StandardScaler</code> from the sklearn's preprocessing library. In addition to dropping the <code>LEADER</code>
            label, I also dropped the <code>MIN</code> column so that the clustering wouldn't be influenced by an athlete's time playing basketball, but rather just the amount of
            points and assists they've made. The results are shown below.
            </p>

            <div class="w3-center">
                <img src="../images/module2_images/kmeans.png" class="w3-image" style="width:70%;">
            </div>

            <p>KMeans clustering works by randomly initializing the location of a user-defined <em>k</em>-amount of centroids. The centroids initial location will be within the space of the data.
            The algorithm then assigns each data point to the nearest centroid. These grouped data points become a cluster.
            That centroid's location is then updated to be the average value of the data within that cluster. KMeans does this for each of the <em>k</em> centroids. The algorithm stops when the locations of the 
            centroids stop moving and all points have been attributed to one of the <em>k</em> clusters.
            </p>
            <p>Because Kmeans clustering starts with randomized centroid locations and only stops when the centroids cease to move, determining
            an accuracy for KMeans label classification and true data labels can be challenging. More specifically, <em>KMeans might cluster differently
            for every implementation - even on the same exact data.</em>
            To account for this, I ran a small simulation that performs KMeans 100 times. I calculated the accuracy of the labels as compared to the 
            <code>LEADER</code> column. The accuracy found two modes. They're shown in their proportion in the following bar chart.
            </p>
            
            <div class="w3-center">
                <img src="../images/module2_images/kmeans_sim.png" class="w3-image" style="width:70%;">
            </div>
            
            <p>KMeans seems to classify the data well! The algorithm seems to generate accuracies of about 90-91% in its classification of leaders versus
            currently active players when assessing just their points and assists. 
            </p>
            
            <strong>Hierarchical Clustering</strong>
            <p>For this portion of the clustering analysis, I used data from the <code>leaguedashplayerstats</code> endpoint from the NBA API. This dataset, also used in the PCA tab, represents each active NBA players' stats over the 2023-2024 NBA season. 
            Please visit the PCA tab to view the original dataset.
            </p>
            
            <p>However, for the hierarchical clustering, I only used a small portion of the dataset. Like the table cleaned for the PCA analysis, this only includes
            the quantitative variables. Ordinal and qualitative have been removed. Then, I sorted the remaining data by the <code>PTS</code> column and chose only the top six entries in the dataframe.
            This generated six records of the top scoring individuals in the NBA over the 2023-2024 season. The data is shown below.
            </p>
            <div style="overflow-x: auto; border: 1px solid #ccc; padding: 8px; max-height: 400px;">
                <table class="w3-table w3-bordered w3-small">
                    <thead>
                        <tr>
                            <th>FGM</th><th>FGA</th><th>FG_PCT</th><th>FG3M</th><th>FG3A</th><th>FG3_PCT</th>
                            <th>FTM</th><th>FTA</th><th>FT_PCT</th><th>OREB</th><th>DREB</th><th>REB</th>
                            <th>AST</th><th>TOV</th><th>STL</th><th>BLK</th><th>BLKA</th><th>PF</th><th>PFD</th>
                            <th>PTS</th><th>PLUS_MINUS</th><th>NAME</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>804</td><td>1652</td><td>0.487</td><td>284</td><td>744</td><td>0.382</td><td>478</td><td>608</td><td>0.786</td><td>59</td><td>588</td><td>647</td><td>686</td><td>282</td><td>99</td><td>38</td><td>50</td><td>149</td><td>477</td><td>2370</td><td>319</td><td>Luka Dončić</td></tr>
                        <tr><td>796</td><td>1487</td><td>0.535</td><td>95</td><td>269</td><td>0.353</td><td>567</td><td>649</td><td>0.874</td><td>65</td><td>350</td><td>415</td><td>465</td><td>162</td><td>150</td><td>67</td><td>77</td><td>184</td><td>480</td><td>2254</td><td>613</td><td>Shai Gilgeous-Alexander</td></tr>
                        <tr><td>837</td><td>1369</td><td>0.611</td><td>34</td><td>124</td><td>0.274</td><td>514</td><td>782</td><td>0.657</td><td>196</td><td>645</td><td>841</td><td>476</td><td>250</td><td>87</td><td>79</td><td>90</td><td>210</td><td>604</td><td>2222</td><td>339</td><td>Giannis Antetokounmpo</td></tr>
                        <tr><td>790</td><td>1648</td><td>0.479</td><td>211</td><td>526</td><td>0.401</td><td>421</td><td>497</td><td>0.847</td><td>43</td><td>235</td><td>278</td><td>519</td><td>186</td><td>70</td><td>13</td><td>64</td><td>144</td><td>480</td><td>2212</td><td>512</td><td>Jalen Brunson</td></tr>
                        <tr><td>822</td><td>1411</td><td>0.583</td><td>83</td><td>231</td><td>0.359</td><td>358</td><td>438</td><td>0.817</td><td>223</td><td>753</td><td>976</td><td>708</td><td>237</td><td>108</td><td>68</td><td>68</td><td>194</td><td>426</td><td>2085</td><td>682</td><td>Nikola Jokić</td></tr>
                        <tr><td>718</td><td>1558</td><td>0.461</td><td>190</td><td>532</td><td>0.357</td><td>423</td><td>506</td><td>0.836</td><td>52</td><td>378</td><td>430</td><td>405</td><td>241</td><td>101</td><td>42</td><td>56</td><td>141</td><td>336</td><td>2049</td><td>432</td><td>Anthony Edwards</td></tr>
                    </tbody>
                </table>
            </div>
            
            <p>Note that the only acception to this dataset compared to the other clustering datasets is that I included the name of the athlete so we could see which individuals were clustered together.
            In the following DBSCAN clustering, the names were excluded. 
            </p>
            
            <p>To cluster the data, I used the <code>scipy.cluster.hierarchy</code> library. In creating the dendrogram, I used the <em>ward</em> method. This method of hierarchical clustering iteratively
            goes through each of the records and asseses which subsequent record is closest in Euclidean distance. When the subsequent record is chosen, the pairs are clustered together.
            After a first pass through the data, paired records are treated as a single cluster. Clusters or unpaired records are then merged with whatever unit adds the least variance to the overall grouping. 
            The dendrogram below illustrates these groupings. Note that the lowest level forks on the dendrogram represent the records with the smallest Euclidean distance at the difference between the heights of a given fork and that of the next level
            equal the variance added to the cluster by the subsequent grouping. The results of the <em>ward</em> algorithm are illustrated in the dendrogram below. 
            </p>
            
            <div class="w3-center">
                <img src="../images/module2_images/hierarchical_clustering.png" class="w3-image" style="width:70%;">
            </div>            
            
            <p>Clustered on the left are three dominant athletes — Luka Dončić, Anthony Edwards, and Jalen Brunson — all of whom play as <em>guards</em> in the NBA. 
            This position typically involves skilled ball handling, playmaking, and scoring potential. 
            Guards are responsible for setting the pace on offense and usually defend the perimeter against outside shooting threats.
            </p>

            <p>The other major cluster includes Nikola Jokić and Giannis Antetokounmpo, two athletes who have recently won the NBA’s Most Valuable Player (MVP) award. 
            Both serve as versatile frontcourt players who operate close to the basket on both ends of the court — defending the rim and scoring efficiently near the hoop. 
            Shai Gilgeous-Alexander, a prospective MVP candidate for the 2024–2025 season, joins them at the next merged fork. 
            While he also plays as a guard, Shai, Jokić, and Antetokounmpo may be grouped together due to their overwhelming importance to their respective teams. 
            Though all have had strong teammates, these three are clearly the top offensive option for their squads. 
            That centrality may boost their individual stats and account for their similarity in this clustering.
            </p>

            
            <strong>DBSCAN</strong>
            <p>The DBSCAN clustering algorithm works by associated data points based on density. The algorithm takes two parameters, 
            a distance metric and quantity metric. The algorithm starts by checking every single point. If a point has an amount of
            neighbors within the distance metric exceeding the quantity metric, the given point is considered a core point. This core 
            point and its neighbors are considered a cluster. To expand on the cluster, the algorithm iterates through each of the 
            neighboring points and determines if they can be a core point based on the distance and quantity metrics. When neighbors 
            to a core point no longer become core points themselves, the current cluster is grouped and the algorithm moves on to the 
            next unclustered data points. The algorithm stops when no more core points are found. Points without a cluster are considered 
            outliers.
            </p>
            
            <p>I've applied the DBSCAN algorithm to a dataset I've already used in the PCA tab. Like the values in the hierarchical
            clustering, this cleaned dataset also comes from <code>leaguedashplayerstats</code> endpoint from the NBA API. Like the other clustering
            algorithms, I've removed all qualitative and ordinal features and normalized the data. While I expand more on this in the PCA 
            tab, the first three rows of the cleaned dataset are:
            </p>
            <!-- Cleaned table -->
            <div style="overflow-x: auto; border: 1px solid #ccc; padding: 8px; max-height: 300px;">
                <table class="w3-table w3-bordered w3-small">
                    <thead>
                        <tr>
                            <th>FGM</th><th>FGA</th><th>FG_PCT</th><th>FG3M</th><th>FG3A</th><th>FG3_PCT</th><th>FTM</th><th>FTA</th><th>FT_PCT</th><th>OREB</th><th>DREB</th><th>REB</th><th>AST</th><th>TOV</th><th>STL</th><th>BLK</th><th>BLKA</th><th>PF</th><th>PFD</th><th>PTS</th><th>PLUS_MINUS</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td>54</td><td>121</td><td>0.446</td><td>13</td><td>50</td><td>0.260</td><td>15</td><td>23</td><td>0.652</td><td>14</td><td>36</td><td>50</td><td>20</td><td>14</td><td>10</td><td>3</td><td>8</td><td>22</td><td>13</td><td>136</td><td>18</td></tr>
                        <tr><td>83</td><td>196</td><td>0.423</td><td>69</td><td>169</td><td>0.408</td><td>17</td><td>19</td><td>0.895</td><td>9</td><td>55</td><td>64</td><td>30</td><td>12</td><td>9</td><td>4</td><td>3</td><td>49</td><td>20</td><td>252</td><td>50</td></tr>
                        <tr><td>18</td><td>62</td><td>0.290</td><td>10</td><td>39</td><td>0.256</td><td>2</td><td>2</td><td>1.000</td><td>2</td><td>16</td><td>18</td><td>5</td><td>8</td><td>1</td><td>2</td><td>3</td><td>6</td><td>1</td><td>48</td><td>-51</td></tr>
                    </tbody>
                </table>
            </div>            
           
            <p>After applying a Gaussian normalization with the <code>StandardScalar</code> function from the sklearn.preprocessing library, I applied 
            principal component analysis with two components. The results are plotted and I've color coded the athletes based on whether or not they consistently
            started or came off the bench for the 2023-2024 season.
            </p>
            
            <div class="w3-center">
                <img src="../images/module2_images/pca2.png" class="w3-image" style="width:100%; max-width:1000px;">
            </div>
            
            <p>Note that there is clustering of the bench players towards the left of the graph. With my classification of starter and bench player, I could assess
            the accuracy of the DBSCAN algorithm. After tweaking the parameters of the DBSCAN algorithm by hand, I was able to achieve an <strong>accuracy score of about
            87%</strong>. This score was calculated by taking the classification labels of the DBSCAN algorithm and comparing them to my classifications of bench or starting athlete
            in the original data. Accuracy was calculated by dividing the number of consistent classifications by the total number of athletes in the dataset. The results of
            the clustering are shown below.
            </p>
            
            <div class="w3-center">
                <img src="../images/module2_images/dbscan.png" class="w3-image" style="width:100%; max-width:1000px;">
            </div>
            
            <p>The image shows the grey cluster is largely centered in the same location for that of the actual classifications in the previous figure. 
            These datapoints are responsible for the decent accuracy score mentioned above. However, because DBSCAN is a <em>density</em> based clustering algorithm,
            it is no suprise that the algorithm fails to classify correctly the spread of bench players that deviate from the grey cluster.
            </p>
            
            <p> Ultimately, the <strong>conclusions</strong> from this tab are that
            <ul>
                <li>The leading scorers and assist makers seem to be from an inherently separate population compared to the current active players with the most minutes. 
                Kmeans clustering of the data revealed an accuracy of around 90% in classifying the populations from each other.</li>
                <li>Hierarchical clustering can be shown to group athletes of similar position on the court and talent prominence within their team</li>
                <li>DBSCAN algorithm can work to identify the core of where the bench players reside in a PCA analysis, but that density based clustering algorithms struggle
                to account for spreads of data away from the main cluster that are still within the given classification.</li>
            </ul>
            
            <!-- Download Section -->
            <strong>Data Download</strong>
            <div class="w3-panel w3-leftbar w3-light-grey w3-margin-top">
                <ul>
                    <li>The raw data from <code>leaguedashplayerstats</code> for the 2023-2024 season can be downloaded <a href="../data/module2_data/leaguedashplayerstats.csv" download>here</a>.</li>
                    <li>The trimmed and cleaned version for the hierarchical clustering can be downloaded <a href="../data/module2_data/top_6_scorers.csv" download>here</a>.</li>
                    <li>And the cleaned version used for DBSCAN via PCA that only uses the selected features in the table: <a href="../data/module2_data/pca_cleaned_data.csv" download>here</a>.</li>
                    <li>The notebook used to generate the clustering figures can be found <a href="../notebooks/gather_data_clustering.ipynb" download>here</a>.</li>
                </ul>
            </div>

        </div>
    </div>
</div>

<!-- Footer -->
<footer class="w3-center w3-light-grey w3-padding-48 w3-large">
  <p>This analysis is done for the University of Colorado, Boulder, as part of the curriculum for CS 5612</p>
  <p>Template provided <a href="https://www.w3schools.com/w3css/default.asp" target="_blank" class="w3-hover-text-green">w3.css</a></p>
</footer>

</body>
</html>
